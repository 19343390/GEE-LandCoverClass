{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MySegments\n",
    "import MyVisualiser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "from os import mkdir\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import statsmodels.stats.weightstats as smws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_ttost(x,y,thresh):\n",
    "    #return the p-value for the lower threshhold test\n",
    "    #http://jpktd.blogspot.se/2012/10/tost-statistically-significant.html\n",
    "    pv1 = smws.ttost_ind(np.array(x).flatten(), np.array(y).flatten(),-thresh,thresh, usevar='unequal')[1][1]    \n",
    "    return pv1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Non-inferiority test----\n",
      "----optimize accuracy----\n",
      "p-Value:  0.25 \tnon-inferiority margin:  5.0 %\n",
      "-------- MI -------\n",
      "better model found with 10 features (initially  226 )\n",
      "best estimating model saved at: ./New_Paper_Results/Beijing/MI_acc_p_0.25_ninf_5.0_10.pkl\n",
      "previous top-score\n",
      "     mean_score_time  mean_fit_time  n_features  mean_test_Accuracy  \\\n",
      "580         0.035607       0.087131         226            0.914875   \n",
      "\n",
      "     std_test_Accuracy  \n",
      "580           0.026438  \n",
      "reduced\n",
      "     mean_score_time  mean_fit_time  n_features  mean_test_Accuracy  \\\n",
      "819         0.009333       0.374519          10             0.87724   \n",
      "\n",
      "     std_test_Accuracy  \n",
      "819           0.025467  \n",
      "-------- F-Score -------\n",
      "better model found with 21 features (initially  226 )\n",
      "best estimating model saved at: ./New_Paper_Results/Beijing/F-Score_acc_p_0.25_ninf_5.0_21.pkl\n",
      "previous top-score\n",
      "     mean_score_time  mean_fit_time  n_features  mean_test_Accuracy  \\\n",
      "664         0.040608       0.083152         226            0.937276   \n",
      "\n",
      "     std_test_Accuracy  \n",
      "664           0.024292  \n",
      "reduced\n",
      "     mean_score_time  mean_fit_time  n_features  mean_test_Accuracy  \\\n",
      "654         0.011195       0.057529          21            0.896953   \n",
      "\n",
      "     std_test_Accuracy  \n",
      "654           0.010382  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = [ 'MI', 'F-Score']\n",
    "clfs = []\n",
    "cv_results = []\n",
    "\n",
    "#load best estimators and cv results\n",
    "\n",
    "file_path = './New_Paper_Results/Beijing/'\n",
    "for model in models:    \n",
    "    for file in os.listdir(file_path + model):\n",
    "        if file.endswith('.pkl'):\n",
    "            #print(os.path.join('./Results/' + model, file))\n",
    "            clfs.append(joblib.load(os.path.join(file_path + model, file)))\n",
    "            #print(joblib.load(os.path.join('./Results_CV9/' + model, file)))\n",
    "        if file.endswith('.csv'):\n",
    "            cv_results.append(pd.read_csv(os.path.join(file_path + model, file), sep='\\t'))#, header=1))\n",
    "\n",
    "#Load Data\n",
    "#mypath = 'Test'\n",
    "#onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "    \n",
    "#Get labelled data\n",
    "#sc = MySegments.SegmentCollection(folder = mypath, segments_path=onlyfiles, labels_path = 'labels.csv', classes_path='class_names.csv')\n",
    "#idx,X,y = sc.get_labelled()\n",
    "\n",
    "#split train and test data, maintaining class distributions\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify = y)\n",
    "\n",
    "print('----Non-inferiority test----')\n",
    "print('----optimize accuracy----')\n",
    "p_val = 0.25\n",
    "ninf_margin = 0.05\n",
    "print('p-Value: ', p_val, '\\tnon-inferiority margin: ', ninf_margin*100, '%')\n",
    "\n",
    "for i,(model, clf, cv_result) in enumerate(zip(models, clfs, cv_results)):\n",
    "    # ------Non inferiority test----\n",
    "    # test if mean_test_score with std_test_score is NOT INFERIOR \n",
    "    # to the mean_test_score with std_test_score of the highest ranking classifier\n",
    "    # H_0: µ_1 < µ_2 + delta_lower -> µ_1 may be inferior to µ_2\n",
    "    # H_A: µ_1 >= µ_2 + delta_lower -> µ_1 is NOT inferior to µ_2 \n",
    "    \n",
    "    #filter to get individual cross-validation results\n",
    "    filter_col = [col for col in cv_result if col.startswith('split') & col.endswith('_test_Accuracy')]\n",
    "    n_obs = len(filter_col) #number of observations (cross-validations)\n",
    "    \n",
    "        \n",
    "    #get highest ranked estimator\n",
    "    top_score = cv_result.sort_values('rank_test_Accuracy', ascending=True).head(1)\n",
    "    top_score_mean = top_score['mean_test_Accuracy']\n",
    "    top_score_std = top_score['std_test_Accuracy']\n",
    "    top_scores = top_score[filter_col]\n",
    "    top_n_features = top_score['n_features']\n",
    "    \n",
    "    #print(top_score)\n",
    "    \n",
    "    #compute t-test against top_score Non-inferiority\n",
    "    cv_result['p_val'] = cv_result.apply(lambda row: my_ttost(row[filter_col], top_scores, ninf_margin), axis=1)\n",
    "    filtered = cv_result[cv_result['p_val'] <= p_val]\n",
    "    filtered = filtered.sort_values('n_features',ascending=True).head(1)\n",
    "    \n",
    "    #store the better classifier, if there is one\n",
    "    top_n = top_score.iloc[0]['n_features']\n",
    "    filt_n = filtered.iloc[0]['n_features']\n",
    "    print('--------',model,'-------')\n",
    "    if top_n <= filt_n:\n",
    "        print('kept classifier with', top_n, 'features')\n",
    "        print(top_score[['mean_score_time','mean_fit_time', 'n_features', 'mean_test_Accuracy', 'std_test_Accuracy']])\n",
    "    else:\n",
    "        print('better model found with', filt_n, 'features (initially ', top_n,')')\n",
    "        filt_C = filtered.iloc[0]['param_classify__estimator__C']\n",
    "        filt_gamma = filtered.iloc[0]['param_classify__estimator__gamma']\n",
    "        clf.set_params(reduce_dim__k = filt_n, classify__estimator__C = filt_C, classify__estimator__gamma = filt_gamma)\n",
    "        #Store best estimator\n",
    "        best_filename = file_path + model +'_acc_' + 'p_' + str(p_val) + '_ninf_' + str(ninf_margin*100) + '_'+ str(filt_n) + '.pkl'\n",
    "        joblib.dump(clf, best_filename)\n",
    "        print('best estimating model saved at:', best_filename)    \n",
    "        print('previous top-score')\n",
    "        print(top_score[['mean_score_time','mean_fit_time', 'n_features', 'mean_test_Accuracy', 'std_test_Accuracy']])\n",
    "        print('reduced')\n",
    "        print(filtered[['mean_score_time','mean_fit_time', 'n_features', 'mean_test_Accuracy', 'std_test_Accuracy']])\n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
